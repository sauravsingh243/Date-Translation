{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {
    "id": "Hz7r1Q83JGaq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(position, maxLength):\n",
    "  res = np.zeros(maxLength)\n",
    "  res[position] = 1\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloveOutput = {'0': oneHot(0,13), '1': oneHot(1,13), '2': oneHot(2,13), '3': oneHot(3,13), '4': oneHot(4,13),\n",
    "                '5': oneHot(5,13), '6': oneHot(6,13), '7': oneHot(7,13), '8': oneHot(8,13), '9': oneHot(9,13),\n",
    "                '-': oneHot(10,13), '<sot>': oneHot(11,13), '<eot>': oneHot(12,13)}\n",
    "reverseGloveOutput = {0 : '0', 1 : '1', 2 : '2', 3 : '3', 4 : '4', 5 : '5', 6 : '6', 7 : '7', 8 : '8', 9 : '9', 10 : '-', 11 : '<sot>', 12 : '<eot>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "id": "0ZyDJeL9YZn2"
   },
   "outputs": [],
   "source": [
    "gloveInput = {' ': oneHot(0,33), '/': oneHot(1,33), '0': oneHot(2,33), '1': oneHot(3,33), '2': oneHot(4,33), '3': oneHot(5,33),\n",
    "        '4': oneHot(6,33), '5': oneHot(7,33), '6': oneHot(8,33), '7': oneHot(9,33), '8': oneHot(10,33), '9': oneHot(11,33),\n",
    "        'a': oneHot(12,33), 'b': oneHot(13,33), 'c': oneHot(14,33), 'd': oneHot(15,33), 'e': oneHot(16,33), 'f': oneHot(17,33),\n",
    "        'g': oneHot(18,33), 'h': oneHot(19,33), 'i': oneHot(20,33), 'j': oneHot(21,33), 'l': oneHot(22,33), 'm': oneHot(23,33), \n",
    "        'n': oneHot(24,33), 'o': oneHot(25,33), 'p': oneHot(26,33), 'r': oneHot(27,33), 's': oneHot(28,33), 't': oneHot(29,33),\n",
    "        'u': oneHot(30,33), 'v': oneHot(31,33), 'y': oneHot(32,33)}\n",
    "\n",
    "reverseGloveInput = {0 : ' ', 1 : '/', 2 : '0', 3 : '1', 4 : '2', 5 : '3',  6 : '4', 7 : '5', 8 : '6',  9 : '7',  10 : '8',  11 : '9', 12 : 'a', 13 : 'b', 14 : 'c', 15 : 'd',\n",
    "        16 : 'e', 17 : 'f', 18 : 'g', 19 : 'h', 20 : 'i', 21 : 'j', 22 : 'l', 23 : 'm' , 24 : 'n' , 25 : 'o', 26 : 'p', 27 : 'r', 28 : 's', 29 : 't', 30 : 'u', 31 : 'v',\n",
    "        32 : 'y'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6mrj2IQ3sxt",
    "outputId": "cedcacc5-aa46-49bc-87d8-2a4a62bb0e72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "id": "XNXRtWiTL8sh"
   },
   "outputs": [],
   "source": [
    "days = ['mon','monday','tue','tuesday','wed','wednesday','thu','thursday','fri','friday','sat','saturday','sun','sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "id": "wO4B3FC-YRx2"
   },
   "outputs": [],
   "source": [
    "def preProcess(inputWithOutPreProcess):\n",
    "  wordlist = inputWithOutPreProcess.split()\n",
    "  for j in wordlist:\n",
    "    if j in days:\n",
    "      inputWithOutPreProcess = inputWithOutPreProcess.replace(j, \"\\b\")\n",
    "  return inputWithOutPreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "id": "8RboKfRXKqJ4"
   },
   "outputs": [],
   "source": [
    "path = open('/home/saurav/DLNP Assignment/DLNLP_ASS4/Assignment4aDataset.txt','r')\n",
    "data = path.readlines()\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "  data[i] = data[i].strip()\n",
    "  data[i] = data[i].lower()\n",
    "  data[i] = data[i].split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "y7ob0ewTJ4Rc",
    "outputId": "092e9080-413e-4c4a-eee6-6818bcbd7382"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'may 20 2034'</td>\n",
       "      <td>'2034-05-20'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'9 may 1630'</td>\n",
       "      <td>'1630-05-09'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'15/03/2014'</td>\n",
       "      <td>'2014-03-15'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'mar 16 1675'</td>\n",
       "      <td>'1675-03-16'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'jun 16 1640'</td>\n",
       "      <td>'1640-06-16'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'friday 1791 2 09'</td>\n",
       "      <td>'1791-09-02'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'wed 1776 11 september'</td>\n",
       "      <td>'1776-09-11'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'1833 9 jun'</td>\n",
       "      <td>'1833-06-09'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'sun 26 oct 1788'</td>\n",
       "      <td>'1788-10-26'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'1685 30 oct'</td>\n",
       "      <td>'1685-10-30'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     input        output\n",
       "0            'may 20 2034'  '2034-05-20'\n",
       "1             '9 may 1630'  '1630-05-09'\n",
       "2             '15/03/2014'  '2014-03-15'\n",
       "3            'mar 16 1675'  '1675-03-16'\n",
       "4            'jun 16 1640'  '1640-06-16'\n",
       "5       'friday 1791 2 09'  '1791-09-02'\n",
       "6  'wed 1776 11 september'  '1776-09-11'\n",
       "7             '1833 9 jun'  '1833-06-09'\n",
       "8        'sun 26 oct 1788'  '1788-10-26'\n",
       "9            '1685 30 oct'  '1685-10-30'"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = data, columns = ['input', 'output'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "id": "ezr4r05qBmjN"
   },
   "outputs": [],
   "source": [
    "inputX = np.char.lower(np.char.replace(list(df['input']),\"'\",\"\"))\n",
    "inputY = np.char.lower(np.char.replace(list(df['output']),\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "id": "LPqkdpJY49Qg"
   },
   "outputs": [],
   "source": [
    "def preProcess1(sample):\n",
    "  tokens = sample.split()\n",
    "  filteredTokens = []\n",
    "  for i in tokens:\n",
    "    if i not in days:\n",
    "      filteredTokens.append(i)\n",
    "  charList = []\n",
    "  n = len(filteredTokens)\n",
    "  for i in range(n):\n",
    "    currCharList = list(filteredTokens[i])\n",
    "    if(i != n-1):\n",
    "      currCharList.append(' ')\n",
    "    charList.extend(currCharList)\n",
    "  return charList\n",
    "\n",
    "\n",
    "def preProcess2(charList, maxLength):\n",
    "  for i in range(maxLength - len(charList)):\n",
    "    charList.append(' ')\n",
    "  vectorRep = []\n",
    "  for i in charList:\n",
    "    vectorRep.append(gloveInput[i]);\n",
    "  return vectorRep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "id": "7kotJrSj6ext"
   },
   "outputs": [],
   "source": [
    "completeCharList = [preProcess1(sample) for sample in inputX]\n",
    "maxLength = 0\n",
    "for charList in completeCharList:\n",
    "  maxLength = max(maxLength, len(charList))\n",
    "\n",
    "train_X = [preProcess2(charList, maxLength) for charList in completeCharList]\n",
    "train_X = np.array(train_X)\n",
    "\n",
    "\n",
    "\n",
    "train_Y = []\n",
    "for sample in inputY:\n",
    "  temp = list(sample)\n",
    "  temp.insert(0, '<sot>')\n",
    "  temp.append('<eot>')\n",
    "  train_Y.append(temp)\n",
    "train_Y = np.array(train_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "id": "IdksH8UkB8Ok"
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in train_Y:\n",
    "  ss = []\n",
    "  for j in i:\n",
    "    ss.append(gloveOutput[j])\n",
    "  y.append(ss)\n",
    "train_Y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Xpyc9gtDP67",
    "outputId": "b1b6c2ba-3cce-41a4-8f1b-e065eaba9ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 17, 33)\n",
      "(40000, 12, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "id": "qiYHaPbAmTxM"
   },
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_X)\n",
    "train_y = torch.Tensor(train_Y)\n",
    "train_y = train_y.type(torch.LongTensor)\n",
    "dataset = TensorDataset(train_x,train_y)\n",
    "training, validation = random_split(dataset, [36000, 4000])\n",
    "batch_size = 400\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=training, batch_size=batch_size, shuffle=True)\n",
    "valLoader = torch.utils.data.DataLoader(dataset=validation, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, inputSize, outputSize, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.LSTM = nn.LSTM(inputSize, outputSize, num_layers = num_layers, batch_first = True, bidirectional = False, dropout = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, (hidden, cell) = self.LSTM(x)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.outputSize = outputSize\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.LSTM = nn.LSTM(inputSize, hiddenSize, num_layers = num_layers, dropout = dropout, batch_first = True, bidirectional = False)\n",
    "        self.FC = nn.Linear(hiddenSize, inputSize)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        output, (hidden, cell) = self.LSTM(x.float(), (hidden, cell))\n",
    "        output = self.FC(output)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize, num_layers, dropout):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.outputSize = outputSize\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.linear1 = nn.Linear(inputSize, hiddenSize)\n",
    "        self.attentionLinear1 = nn.Linear(self.hiddenSize * 2, 17)\n",
    "        self.attentionLinear2 = nn.Linear(self.hiddenSize*2, self.inputSize)\n",
    "\n",
    "        self.lstm = nn.LSTM(inputSize, hiddenSize, num_layers, batch_first = True, dropout = dropout, bidirectional = False)   \n",
    "        \n",
    "        self.linear2 = nn.Linear(hiddenSize, outputSize)\n",
    "            \n",
    "    def forward(self, input, hidden, cell, encoderOutputs):  \n",
    "        \n",
    "        out = self.linear1(input)\n",
    "        attentionWeights = F.softmax(self.attentionLinear1(torch.cat((out, (hidden.squeeze(0)).unsqueeze(1)), 2)), dim=2)\n",
    "        weights = torch.bmm(attentionWeights, encoderOutputs)\n",
    "        output = torch.cat((out, weights), 2)\n",
    "        output = self.attentionLinear2(output)\n",
    "        output = F.relu(output)\n",
    "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
    "        output = self.linear2(output)\n",
    "        # return output, hidden, cell\n",
    "        return output, hidden, cell, attentionWeights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, input, target = None, teacherForceRatio = 0.5):\n",
    "        batchSize = input.shape[0]\n",
    "        targetLength = train_y.shape[1]\n",
    "        targetVocabSize = train_y.shape[2]\n",
    "        outputTensor = torch.zeros(batchSize, targetLength, targetVocabSize).to(device)\n",
    "        attentionweightTensor = torch.zeros(batchSize, targetLength, 17).to(device)\n",
    "        encoderOutput, hidden, cell = self.encoder(input)\n",
    "        # print(hidden.shape)\n",
    "        if(target == None):\n",
    "            x = torch.Tensor(gloveOutput['<sot>']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        else:\n",
    "            x = target[:, 0, :].unsqueeze(1)\n",
    "        for t in range(1, targetLength):\n",
    "            # output, hidden, cell = self.decoder(x.float(), hidden, cell)\n",
    "            output, hidden, cell, attentionWeight = self.decoder(x.float(), hidden, cell, encoderOutput)\n",
    "            # print(attentionWeight)\n",
    "            outputTensor[:, t-1, :] = output.squeeze(dim = 1)\n",
    "            attentionweightTensor[:, t-1, :] = attentionWeight.squeeze(dim = 1)\n",
    "            x = target[:, t, :].unsqueeze(1) if random.random() < teacherForceRatio else output\n",
    "\n",
    "        # return outputTensor\n",
    "        return outputTensor, attentionweightTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, lr = 30, 0.003\n",
    "encoderNetwork = Encoder(inputSize = 33, outputSize = 200, num_layers = 1, dropout = 0).to(device)\n",
    "decoderNetwork = AttentionDecoder(inputSize = 13, hiddenSize = 200, outputSize = 13, num_layers = 1, dropout = 0).to(device)\n",
    "model = Seq2Seq(encoder = encoderNetwork, decoder = decoderNetwork).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 69.36it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 44.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss: 0.05252940642337004 Validation Loss: 0.05411229319870472 accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 69.84it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Loss: 0.03197866510599852 Validation Loss: 0.03900008499622345 accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.88it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 42.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training Loss: 0.024725930775619215 Validation Loss: 0.03671524487435818 accuracy: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.96it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training Loss: 0.019410224760779075 Validation Loss: 0.03152660895138979 accuracy: 0.27499999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.82it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training Loss: 0.015586569910455081 Validation Loss: 0.024837260879576207 accuracy: 3.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 64.02it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 42.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training Loss: 0.01206952908800708 Validation Loss: 0.017404238879680633 accuracy: 17.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.96it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training Loss: 0.007862167440665264 Validation Loss: 0.00961513314396143 accuracy: 54.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.96it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training Loss: 0.0049532951761244075 Validation Loss: 0.006168743409216404 accuracy: 70.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 57.68it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 41.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training Loss: 0.0030410937848500907 Validation Loss: 0.003900349885225296 accuracy: 82.27499999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.49it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training Loss: 0.0019570768784938587 Validation Loss: 0.0024364445824176075 accuracy: 89.60000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.83it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training Loss: 0.001215667543389524 Validation Loss: 0.0013212976919021457 accuracy: 95.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.77it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 42.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training Loss: 0.0008259967564501696 Validation Loss: 0.0009980594681110234 accuracy: 96.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.98it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training Loss: 0.0006164926018552958 Validation Loss: 0.000693727092584595 accuracy: 96.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.53it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 42.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training Loss: 0.00046193175561105214 Validation Loss: 0.0005660205730237067 accuracy: 97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.77it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 42.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training Loss: 0.0003825703299500876 Validation Loss: 0.0005815974640427157 accuracy: 96.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 64.14it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training Loss: 0.0003580786950705159 Validation Loss: 0.0004729201376903802 accuracy: 97.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 64.63it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training Loss: 0.0003073939700294027 Validation Loss: 0.00044374408316798507 accuracy: 96.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 64.03it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 42.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training Loss: 0.0002812820622542252 Validation Loss: 0.0004155768285272643 accuracy: 97.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 47.89it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 30.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training Loss: 0.0002598010933272437 Validation Loss: 0.0004107927205041051 accuracy: 97.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:02<00:00, 44.61it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 31.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training Loss: 0.00026600978962960654 Validation Loss: 0.000394236232386902 accuracy: 97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:02<00:00, 44.96it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 30.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training Loss: 0.0002371323473198572 Validation Loss: 0.00039673236606176945 accuracy: 97.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 56.96it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 41.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training Loss: 0.00022233656980258983 Validation Loss: 0.0004038830637000501 accuracy: 97.02499999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 68.96it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training Loss: 0.0002215731290359852 Validation Loss: 0.0003762264808756299 accuracy: 97.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 69.04it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training Loss: 0.00020581343305821066 Validation Loss: 0.0006809134007198736 accuracy: 95.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 69.05it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 41.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training Loss: 0.0009244546707325046 Validation Loss: 0.0004341923107858747 accuracy: 96.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 58.68it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training Loss: 0.00021811998522025533 Validation Loss: 0.0003873540612403303 accuracy: 96.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 68.98it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 42.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training Loss: 0.00020652352500797455 Validation Loss: 0.0003705923445522785 accuracy: 97.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 64.61it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training Loss: 0.0001976221601378509 Validation Loss: 0.0003859502365230583 accuracy: 97.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 63.54it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training Loss: 0.00019160919940380456 Validation Loss: 0.00038080657832324506 accuracy: 97.02499999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 69.71it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 44.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training Loss: 0.00019680718370283204 Validation Loss: 0.0003524571380694397 accuracy: 97.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainLoss = []\n",
    "valLoss = []\n",
    "for epoch in range(epochs):\n",
    "    tLoss = 0\n",
    "    vLoss = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for x, y in tqdm(trainLoader):\n",
    "        x, y = x.to(device), y.to(device) \n",
    "        # output = model(x, y)\n",
    "        output, weight = model(x, y)\n",
    "        optimiser.zero_grad()\n",
    "        loss = criterion(output[:, 1:-1, :], y[:, 1:-1, :].float())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        tLoss += loss.item()\n",
    "        \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valLoader):\n",
    "            x, y = x.to(device), y.to(device) \n",
    "            # output = model(x, y, 0)\n",
    "            output, weight = model(x, y, 0)\n",
    "            loss = criterion(output[:, 1:-1, :], y[:, 1:-1, :].float())\n",
    "            vLoss += loss.item()\n",
    "\n",
    "            predictedY = torch.argmax(output, dim = 2)\n",
    "            trueY = torch.argmax(y, dim = 2)\n",
    "            for batch in range(y.shape[0]):\n",
    "                predictedIndexList = list(predictedY[batch].cpu().detach().numpy())\n",
    "                predictedDate = ''.join(reverseGlove[i] for i in predictedIndexList[1: -1])\n",
    "                trueIndexList = list(trueY[batch].cpu().detach().numpy())\n",
    "                trueDate = ''.join(reverseGlove[i] for i in trueIndexList[1: -1])\n",
    "                if(predictedDate == trueDate):\n",
    "                    count += 1\n",
    "    \n",
    "    acc = (count/4000)*100\n",
    "    print(f'Epoch {epoch+1} Training Loss: {tLoss/len(trainLoader)} Validation Loss: {vLoss/len(valLoader)} accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jan 24 1752       ,  1752-01-24 ----> 1752-01-24\n",
      "1981 15 december  ,  1981-12-15 ----> 1981-12-15\n",
      "23 february 1806  ,  1806-02-23 ----> 1806-02-23\n",
      "december 18 1874  ,  1874-12-18 ----> 1874-12-18\n",
      "nov 3 2070        ,  2070-11-03 ----> 2070-11-03\n",
      "4/22/27           ,  1827-04-22 ----> 1727-04-22\n",
      "1906 14 july      ,  1906-07-14 ----> 1906-07-14\n",
      "april 3 2000      ,  2000-04-03 ----> 2000-04-03\n",
      "july 7 1559       ,  1559-07-07 ----> 1559-07-07\n",
      "5 march 2016      ,  2016-03-05 ----> 2016-03-05\n"
     ]
    }
   ],
   "source": [
    "for x, y in valLoader:\n",
    "    x, y = x.to(device), y.to(device) \n",
    "    # output = model(x, y, 0)\n",
    "    output, weight = model(x, y, 0)\n",
    "    # print(weight)\n",
    "    inputX = torch.argmax(x, dim = 2)\n",
    "    predictedY = torch.argmax(output, dim = 2)\n",
    "    trueY = torch.argmax(y, dim = 2)\n",
    "    for batch in range(10):\n",
    "        predictedIndexList = list(predictedY[batch].cpu().detach().numpy())\n",
    "        predictedDate = ''.join(reverseGlove[i] for i in predictedIndexList[1: -1])\n",
    "        trueIndexList = list(trueY[batch].cpu().detach().numpy())\n",
    "        trueDate = ''.join(reverseGlove[i] for i in trueIndexList[1: -1])\n",
    "        inputIndexList = list(inputX[batch].cpu().detach().numpy())\n",
    "        inputDate = ''.join(reverseGloveInput[i] for i in inputIndexList)\n",
    "        print(inputDate,', ', trueDate, '---->', predictedDate)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 sept 1918       ----> 1918-09-08\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize(str):\n",
    "    complete_char_list = human_date_to_char_list(str)\n",
    "    train_X = [char_list_to_vector(complete_char_list,17)]\n",
    "    train_X = torch.Tensor(np.array(train_X))\n",
    "    train_X = train_X.to(device)\n",
    "    output, weight = model(train_X, teacherForceRatio = 0)\n",
    "    predictedY = torch.argmax(output, dim = 2)\n",
    "    inputX = torch.argmax(train_X, dim = 2)\n",
    "    batch = 0\n",
    "    predictedIndexList = list(predictedY[batch].cpu().detach().numpy())\n",
    "    predictedDate = ''.join(reverseGloveOutput[i] for i in predictedIndexList[1: -1])\n",
    "    inputIndexList = list(inputX[batch].cpu().detach().numpy())\n",
    "    inputDate = ''.join(reverseGloveInput[i] for i in inputIndexList)\n",
    "    print(inputDate,'---->', predictedDate)\n",
    "    \n",
    "    plt.imshow(weight[:,1:-1,:].squeeze().detach().cpu().numpy())\n",
    "    x_pos = np.arange(len(inputDate))\n",
    "    y_pos = np.arange(len(predictedDate))\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "    plt.xticks(x_pos, list(inputDate), color='black', fontsize='14')\n",
    "    plt.yticks(y_pos, list(predictedDate), color='black', fontsize='14', horizontalalignment='right')\n",
    "    plt.show()\n",
    "        \n",
    "visualize('8 sept 1918')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
