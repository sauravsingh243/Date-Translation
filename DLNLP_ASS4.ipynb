{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hz7r1Q83JGaq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverseGlove = {0 : '0', 1 : '1', 2 : '2', 3 : '3', 4 : '4', 5 : '5', 6 : '6', 7 : '7', 8 : '8', 9 : '9', 10 : '-', 11 : '<sot>', 12 : '<eot>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZyDJeL9YZn2"
   },
   "outputs": [],
   "source": [
    "def to_hardmax_vec(num, max_num):\n",
    "  res = np.zeros(max_num)\n",
    "  res[num] = 1\n",
    "  return res\n",
    "\n",
    "glove = {' ': to_hardmax_vec(0,33),\n",
    "                '/': to_hardmax_vec(1,33),\n",
    "                '0': to_hardmax_vec(2,33),\n",
    "                '1': to_hardmax_vec(3,33),\n",
    "                '2': to_hardmax_vec(4,33),\n",
    "                '3': to_hardmax_vec(5,33),\n",
    "                '4': to_hardmax_vec(6,33),\n",
    "                '5': to_hardmax_vec(7,33),\n",
    "                '6': to_hardmax_vec(8,33),\n",
    "                '7': to_hardmax_vec(9,33),\n",
    "                '8': to_hardmax_vec(10,33),\n",
    "                '9': to_hardmax_vec(11,33),\n",
    "                'a': to_hardmax_vec(12,33),\n",
    "                'b': to_hardmax_vec(13,33),\n",
    "                'c': to_hardmax_vec(14,33),\n",
    "                'd': to_hardmax_vec(15,33),\n",
    "                'e': to_hardmax_vec(16,33),\n",
    "                'f': to_hardmax_vec(17,33),\n",
    "                'g': to_hardmax_vec(18,33),\n",
    "                'h': to_hardmax_vec(19,33),\n",
    "                'i': to_hardmax_vec(20,33),\n",
    "                'j': to_hardmax_vec(21,33),\n",
    "                'l': to_hardmax_vec(22,33),\n",
    "                'm': to_hardmax_vec(23,33),\n",
    "                'n': to_hardmax_vec(24,33),\n",
    "                'o': to_hardmax_vec(25,33),\n",
    "                'p': to_hardmax_vec(26,33),\n",
    "                'r': to_hardmax_vec(27,33),\n",
    "                's': to_hardmax_vec(28,33),\n",
    "                't': to_hardmax_vec(29,33),\n",
    "                'u': to_hardmax_vec(30,33),\n",
    "                'v': to_hardmax_vec(31,33),\n",
    "                'y': to_hardmax_vec(32,33)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6mrj2IQ3sxt",
    "outputId": "cedcacc5-aa46-49bc-87d8-2a4a62bb0e72"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNXRtWiTL8sh"
   },
   "outputs": [],
   "source": [
    "days = ['mon','monday','tue','tuesday','wed','wednesday','thu','thursday','fri','friday','sat','saturday','sun','sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wO4B3FC-YRx2"
   },
   "outputs": [],
   "source": [
    "def preProcess(inputWithOutPreProcess):\n",
    "  wordlist = inputWithOutPreProcess.split()\n",
    "  for j in wordlist:\n",
    "    if j in days:\n",
    "      inputWithOutPreProcess = inputWithOutPreProcess.replace(j, \"\\b\")\n",
    "  return inputWithOutPreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RboKfRXKqJ4"
   },
   "outputs": [],
   "source": [
    "path = open('/home/saurav/DLNP Assignment/DLNLP_ASS4/Assignment4aDataset.txt','r')\n",
    "data = path.readlines()\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "  data[i] = data[i].strip()\n",
    "  data[i] = data[i].lower()\n",
    "  data[i] = data[i].split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "y7ob0ewTJ4Rc",
    "outputId": "092e9080-413e-4c4a-eee6-6818bcbd7382"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = data, columns = ['input', 'output'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezr4r05qBmjN"
   },
   "outputs": [],
   "source": [
    "inputX = np.char.lower(np.char.replace(list(df['input']),\"'\",\"\"))\n",
    "inputY = np.char.lower(np.char.replace(list(df['output']),\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPqkdpJY49Qg"
   },
   "outputs": [],
   "source": [
    "def human_date_to_char_list(sample):\n",
    "  tokens = sample.split()\n",
    "  filtered_tokens = []\n",
    "  for i in tokens:\n",
    "    if i not in days:\n",
    "      filtered_tokens.append(i)\n",
    "  char_list = []\n",
    "  n = len(filtered_tokens)\n",
    "  for i in range(n):\n",
    "    curr_char_list = list(filtered_tokens[i])\n",
    "    if(i != n-1):\n",
    "      curr_char_list.append(' ')\n",
    "    char_list.extend(curr_char_list)\n",
    "  return char_list\n",
    "\n",
    "\n",
    "def char_list_to_vector(char_list, max_len):\n",
    "  curr_len = len(char_list)\n",
    "  for i in range(max_len-curr_len):\n",
    "    char_list.append(' ')\n",
    "\n",
    "  vector_date_rep = []\n",
    "\n",
    "  for i in char_list:\n",
    "    vector_date_rep.append(glove[i]);\n",
    "  \n",
    "  return vector_date_rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kotJrSj6ext"
   },
   "outputs": [],
   "source": [
    "complete_char_list = [human_date_to_char_list(sample) for sample in inputX]\n",
    "max_len = 0\n",
    "for char_list in complete_char_list:\n",
    "  max_len = max(max_len, len(char_list))\n",
    "\n",
    "train_X = [char_list_to_vector(char_list,max_len) for char_list in complete_char_list]\n",
    "train_X = np.array(train_X)\n",
    "\n",
    "\n",
    "\n",
    "train_Y = []\n",
    "for sample in inputY:\n",
    "  temp = list(sample)\n",
    "  temp.insert(0, '<sot>')\n",
    "  temp.append('<eot>')\n",
    "  train_Y.append(temp)\n",
    "train_Y = np.array(train_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JInjWg5t9eMG"
   },
   "outputs": [],
   "source": [
    "hardmax_dict = {'0': to_hardmax_vec(0,13),\n",
    "                '1': to_hardmax_vec(1,13),\n",
    "                '2': to_hardmax_vec(2,13),\n",
    "                '3': to_hardmax_vec(3,13),\n",
    "                '4': to_hardmax_vec(4,13),\n",
    "                '5': to_hardmax_vec(5,13),\n",
    "                '6': to_hardmax_vec(6,13),\n",
    "                '7': to_hardmax_vec(7,13),\n",
    "                '8': to_hardmax_vec(8,13),\n",
    "                '9': to_hardmax_vec(9,13),\n",
    "                '-': to_hardmax_vec(10,13),\n",
    "                '<sot>': to_hardmax_vec(11,13),\n",
    "                '<eot>': to_hardmax_vec(12,13)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdksH8UkB8Ok"
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in train_Y:\n",
    "  ss = []\n",
    "  for j in i:\n",
    "    ss.append(hardmax_dict[j])\n",
    "  y.append(ss)\n",
    "train_Y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Xpyc9gtDP67",
    "outputId": "b1b6c2ba-3cce-41a4-8f1b-e065eaba9ace"
   },
   "outputs": [],
   "source": [
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiYHaPbAmTxM"
   },
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_X)\n",
    "train_y = torch.Tensor(train_Y)\n",
    "train_y = train_y.type(torch.LongTensor)\n",
    "dataset = TensorDataset(train_x,train_y)\n",
    "training, validation = random_split(dataset, [36000, 4000])\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=training, batch_size=4000, shuffle=True)\n",
    "valLoader = torch.utils.data.DataLoader(dataset=validation, batch_size=4000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, inputSize, outputSize, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.LSTM = nn.LSTM(inputSize, outputSize, num_layers = num_layers, batch_first = True, bidirectional = False, dropout = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, (hidden, cell) = self.LSTM(x)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.outputSize = outputSize\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.LSTM = nn.LSTM(inputSize, hiddenSize, num_layers = num_layers, dropout = dropout, batch_first = True, bidirectional = False)\n",
    "        self.FC = nn.Linear(hiddenSize, inputSize)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        output, (hidden, cell) = self.LSTM(x.float(), (hidden, cell))\n",
    "        output = self.FC(output)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize, num_layers, dropout):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.outputSize = outputSize\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.linear1 = nn.Linear(inputSize, hiddenSize)\n",
    "        self.attn = nn.Linear(self.hiddenSize * 2, 17)\n",
    "        self.attn_combine = nn.Linear(self.hiddenSize*2, self.inputSize)\n",
    "\n",
    "        self.lstm = nn.LSTM(inputSize, hiddenSize, num_layers, batch_first = True, dropout = dropout, bidirectional = False)   \n",
    "        \n",
    "        self.linear = nn.Linear(hiddenSize, outputSize)\n",
    "            \n",
    "    def forward(self, input, hidden, cell, encoder_outputs):  \n",
    "        \n",
    "        # print(hidden.shape)\n",
    "        out = self.linear1(input)\n",
    "        # hidden = hidden.squeeze(0)\n",
    "        # hidden = hidden.unsqueeze(1)\n",
    "        # print(out.shape, hidden.shape, torch.cat((out, hidden), 2).shape)\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((out, (hidden.squeeze(0)).unsqueeze(1)), 2)), dim=1)\n",
    "        # print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs)\n",
    "        # print(attn_applied.shape, out.shape, torch.cat((out, attn_applied), 2).shape)\n",
    "        output = torch.cat((out, attn_applied), 2)\n",
    "        output = self.attn_combine(output)\n",
    "        output = F.relu(output)\n",
    "        # print(output.shape)\n",
    "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
    "        output = self.linear(output)\n",
    "        return output, hidden, cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, input, target, teacherForceRatio = 0.5):\n",
    "        batchSize = input.shape[0]\n",
    "        targetLength = target.shape[1]\n",
    "        targetVocabSize = target.shape[2]\n",
    "        outputTensor = torch.zeros(batchSize, targetLength, targetVocabSize).to(device)\n",
    "\n",
    "        encoderOutput, hidden, cell = self.encoder(input)\n",
    "        # print(hidden.shape)\n",
    "        x = target[:, 0, :].unsqueeze(1)\n",
    "        for t in range(1, targetLength):\n",
    "            output, hidden, cell = self.decoder(x.float(), hidden, cell, encoderOutput)\n",
    "            outputTensor[:, t-1, :] = output.squeeze(dim = 1)\n",
    "            x = target[:, t, :].unsqueeze(1) if random.random() < teacherForceRatio else output\n",
    "        \n",
    "        return outputTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, lr = 30, 0.01\n",
    "encoderNetwork = Encoder(inputSize = 33, outputSize = 256, num_layers = 1, dropout = 0).to(device)\n",
    "decoderNetwork = AttentionDecoder(inputSize = 13, hiddenSize = 256, outputSize = 13, num_layers = 1, dropout = 0).to(device)\n",
    "model = Seq2Seq(encoder = encoderNetwork, decoder = decoderNetwork).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoss = []\n",
    "valLoss = []\n",
    "for epoch in range(epochs):\n",
    "    tLoss = 0\n",
    "    vLoss = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for x, y in tqdm(trainLoader):\n",
    "        x, y = x.to(device), y.to(device) \n",
    "        output = model(x, y)\n",
    "        optimiser.zero_grad()\n",
    "        loss = criterion(output[:, 1:-1, :], y[:, 1:-1, :].float())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        tLoss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valLoader):\n",
    "            x, y = x.to(device), y.to(device) \n",
    "            output = model(x, y)\n",
    "            loss = criterion(output[:, 1:-1, :], y[:, 1:-1, :].float())\n",
    "            vLoss += loss.item()\n",
    "\n",
    "            predictedY = torch.argmax(output, dim = 2)\n",
    "            trueY = torch.argmax(y, dim = 2)\n",
    "            for batch in range(40):\n",
    "                predictedIndexList = list(predictedY[batch].cpu().detach().numpy())\n",
    "                predictedDate = ''.join(reverseGlove[i] for i in predictedIndexList[1: -1])\n",
    "                trueIndexList = list(trueY[batch].cpu().detach().numpy())\n",
    "                trueDate = ''.join(reverseGlove[i] for i in trueIndexList[1: -1])\n",
    "                if(predictedDate == trueDate):\n",
    "                    count += 1\n",
    "    \n",
    "    acc = count\n",
    "    print(f'Epoch {epoch+1} Training Loss: {tLoss/len(trainLoader)} Validation Loss: {vLoss/len(valLoader)} accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in trainLoader:\n",
    "    x, y = x.to(device), y.to(device) \n",
    "    output = model(x, y)\n",
    "    predictedY = torch.argmax(output, dim = 2)\n",
    "    trueY = torch.argmax(y, dim = 2)\n",
    "    for batch in range(10):\n",
    "        predictedIndexList = list(predictedY[batch].cpu().detach().numpy())\n",
    "        predictedDate = ''.join(reverseGlove[i] for i in predictedIndexList[1: -1])\n",
    "        trueIndexList = list(trueY[batch].cpu().detach().numpy())\n",
    "        trueDate = ''.join(reverseGlove[i] for i in trueIndexList[1: -1])\n",
    "        print(trueDate, predictedDate)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
